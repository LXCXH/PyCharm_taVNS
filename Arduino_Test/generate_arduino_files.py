#!/usr/bin/env python3
"""
Arduinoæ–‡ä»¶ç”Ÿæˆå™¨
è‡ªåŠ¨ç”ŸæˆESP32-S3 Arduinoé¡¹ç›®æ‰€éœ€çš„æ¨¡å‹æ•°æ®å’Œæ ‡å‡†åŒ–å‚æ•°æ–‡ä»¶

ä½¿ç”¨æ–¹æ³•:
python generate_arduino_files.py

è¦æ±‚:
1. å·²è¿è¡Œconvert_to_tflite.pyç”ŸæˆTFLiteæ¨¡å‹
2. Training_Outputsç›®å½•ä¸­æœ‰æœ€æ–°çš„è®­ç»ƒç»“æœ
"""

import os
import pickle
import json
import glob
import sys
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥data_processoræ¨¡å—
sys.path.append(os.path.dirname(os.path.abspath(__file__)) + '/..')

def find_latest_training_output():
    """æŸ¥æ‰¾æœ€æ–°çš„è®­ç»ƒè¾“å‡ºç›®å½•"""
    training_dirs = glob.glob('Training_Outputs/training_output_*')
    if not training_dirs:
        print("âŒ æœªæ‰¾åˆ°è®­ç»ƒè¾“å‡ºç›®å½•")
        return None
    
    # æŒ‰æ—¶é—´æˆ³æ’åºï¼Œè·å–æœ€æ–°çš„
    latest_dir = max(training_dirs, key=lambda x: os.path.getctime(x))
    print(f"âœ… æ‰¾åˆ°æœ€æ–°è®­ç»ƒç›®å½•: {latest_dir}")
    return latest_dir

def find_latest_tflite_model(prefer_float32=False):
    """æŸ¥æ‰¾æœ€æ–°çš„TFLiteæ¨¡å‹æ–‡ä»¶
    
    Args:
        prefer_float32: æ˜¯å¦ä¼˜å…ˆé€‰æ‹©Float32éé‡åŒ–æ¨¡å‹
    """
    tflite_dirs = glob.glob('TFLite_Output/conversion_*')
    if not tflite_dirs:
        print("âŒ æœªæ‰¾åˆ°TFLiteè½¬æ¢ç›®å½•")
        print("è¯·å…ˆè¿è¡Œ python convert_to_tflite.py")
        return None
    
    # æŒ‰æ—¶é—´æˆ³æ’åºï¼Œè·å–æœ€æ–°çš„
    latest_dir = max(tflite_dirs, key=lambda x: os.path.getctime(x))
    
    # æ ¹æ®åå¥½é€‰æ‹©æ¨¡å‹æ–‡ä»¶
    model_candidates = []
    
    if prefer_float32:
        # ä¼˜å…ˆå°è¯•Float32æ¨¡å‹
        float32_path = os.path.join(latest_dir, 'tavns_model_float32.tflite')
        if os.path.exists(float32_path):
            print(f"âœ… æ‰¾åˆ°Float32éé‡åŒ–æ¨¡å‹: {float32_path}")
            return float32_path
    
    # å°è¯•improvedæ¨¡å‹
    improved_path = os.path.join(latest_dir, 'tavns_model_improved.tflite')
    if os.path.exists(improved_path):
        print(f"âœ… æ‰¾åˆ°é‡åŒ–ä¼˜åŒ–æ¨¡å‹: {improved_path}")
        return improved_path
    
    # æŸ¥æ‰¾å…¶ä»–.tfliteæ–‡ä»¶
    tflite_files = glob.glob(os.path.join(latest_dir, '*.tflite'))
    if tflite_files:
        tflite_path = tflite_files[0]
        print(f"âœ… æ‰¾åˆ°TFLiteæ¨¡å‹: {tflite_path}")
        return tflite_path
    
    print(f"âŒ åœ¨{latest_dir}ä¸­æœªæ‰¾åˆ°TFLiteæ¨¡å‹æ–‡ä»¶")
    return None

def generate_model_data_header(tflite_path, output_path):
    """ç”Ÿæˆæ¨¡å‹æ•°æ®å¤´æ–‡ä»¶"""
    print(f"ğŸ“„ ç”Ÿæˆæ¨¡å‹æ•°æ®å¤´æ–‡ä»¶: {output_path}")
    
    try:
        with open(tflite_path, 'rb') as f:
            data = f.read()
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('#ifndef TAVNS_MODEL_DATA_H\n')
            f.write('#define TAVNS_MODEL_DATA_H\n\n')
            
            # æ£€æµ‹æ¨¡å‹ç±»å‹
            model_type = "Float32éé‡åŒ–" if 'float32' in os.path.basename(tflite_path) else "é‡åŒ–ä¼˜åŒ–"
            esp32_optimized = "æ˜¯" if 'float32' in os.path.basename(tflite_path) else "å¦"
            
            f.write('/*\n')
            f.write(' * TensorFlow Liteæ¨¡å‹æ•°æ®\n')
            f.write(f' * ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}\n')
            f.write(f' * æºæ–‡ä»¶: {tflite_path}\n')
            f.write(f' * æ¨¡å‹å¤§å°: {len(data):,} å­—èŠ‚\n')
            f.write(f' * æ¨¡å‹ç±»å‹: {model_type}\n')
            f.write(f' * ESP32-S3ä¼˜åŒ–: {esp32_optimized}\n')
            f.write(' * \n')
            f.write(' * æ­¤æ–‡ä»¶ç”±generate_arduino_files.pyè‡ªåŠ¨ç”Ÿæˆ\n')
            f.write(' */\n\n')
            
            f.write('const unsigned char tavns_model_data[] = {\n')
            
            for i, byte in enumerate(data):
                if i % 12 == 0:
                    f.write('  ')
                f.write(f'0x{byte:02x}')
                if i < len(data) - 1:
                    f.write(', ')
                if (i + 1) % 12 == 0:
                    f.write('\n')
            
            if len(data) % 12 != 0:
                f.write('\n')
            
            f.write('};\n\n')
            f.write(f'const unsigned int tavns_model_data_len = {len(data)};\n\n')
            
            # æ·»åŠ æ¨¡å‹ä¿¡æ¯
            f.write('// æ¨¡å‹ä¿¡æ¯\n')
            f.write('#define MODEL_INPUT_SIZE 12    // è¡€ç³–åºåˆ—é•¿åº¦\n')
            f.write('#define MODEL_OUTPUT_SIZE 5    // è¾“å‡ºå‚æ•°æ•°é‡\n')
            f.write('#define MODEL_VERSION 3        // TensorFlow Lite Schemaç‰ˆæœ¬\n')
            f.write(f'#define MODEL_SIZE_BYTES {len(data)}  // æ¨¡å‹å¤§å°ï¼ˆå­—èŠ‚ï¼‰\n\n')
            
            f.write('#endif // TAVNS_MODEL_DATA_H\n')
        
        print(f"âœ… æ¨¡å‹æ•°æ®å¤´æ–‡ä»¶ç”Ÿæˆå®Œæˆ ({len(data):,} å­—èŠ‚)")
        return True
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆæ¨¡å‹æ•°æ®å¤´æ–‡ä»¶å¤±è´¥: {e}")
        return False

def generate_scaler_params_from_config(config_path, output_path):
    """ä»è®­ç»ƒé…ç½®æ–‡ä»¶ç”Ÿæˆæ ‡å‡†åŒ–å‚æ•°å¤´æ–‡ä»¶ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
    print(f"ğŸ“„ ä»é…ç½®æ–‡ä»¶ç”Ÿæˆæ ‡å‡†åŒ–å‚æ•°: {config_path}")
    
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = json.load(f)
        
        # ä½¿ç”¨é»˜è®¤çš„æ ‡å‡†åŒ–å‚æ•°ï¼ˆåŸºäºè®ºæ–‡æ•°æ®ï¼‰
        glucose_mean = [10.5] * 12  # é»˜è®¤è¡€ç³–å‡å€¼
        glucose_std = [5.2] * 12    # é»˜è®¤è¡€ç³–æ ‡å‡†å·®
        param_min = [1.0, 0.5, 10.0, 50.0, 1.0]      # [é¢‘ç‡, ç”µæµ, æ—¶é•¿, è„‰å®½, å‘¨æœŸ]
        param_max = [50.0, 5.0, 60.0, 2000.0, 20.0]  # [é¢‘ç‡, ç”µæµ, æ—¶é•¿, è„‰å®½, å‘¨æœŸ]
        
        print("âš ï¸  ä½¿ç”¨é»˜è®¤æ ‡å‡†åŒ–å‚æ•°ï¼ˆåŸºäºè®ºæ–‡æ•°æ®ï¼‰")
        print("   å¦‚éœ€ç²¾ç¡®å‚æ•°ï¼Œè¯·ç¡®ä¿data_processor.pklæ–‡ä»¶å¯ç”¨")
        
        return write_scaler_params_header(output_path, glucose_mean, glucose_std, param_min, param_max, 
                                        source_info=f"é»˜è®¤å‚æ•° (æ¥æº: {config_path})")
        
    except Exception as e:
        print(f"âŒ ä»é…ç½®æ–‡ä»¶ç”Ÿæˆæ ‡å‡†åŒ–å‚æ•°å¤±è´¥: {e}")
        return False

def write_scaler_params_header(output_path, glucose_mean, glucose_std, param_min, param_max, source_info=""):
    """å†™å…¥æ ‡å‡†åŒ–å‚æ•°å¤´æ–‡ä»¶"""
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('#ifndef SCALER_PARAMS_H\n')
            f.write('#define SCALER_PARAMS_H\n\n')
            
            f.write('/*\n')
            f.write(' * æ•°æ®æ ‡å‡†åŒ–å‚æ•°\n')
            f.write(f' * ç”Ÿæˆæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}\n')
            f.write(f' * å‚æ•°æ¥æº: {source_info}\n')
            f.write(' * \n')
            f.write(' * æ­¤æ–‡ä»¶ç”±generate_arduino_files.pyè‡ªåŠ¨ç”Ÿæˆ\n')
            f.write(' * è¯·å‹¿æ‰‹åŠ¨ä¿®æ”¹ï¼Œé‡æ–°ç”Ÿæˆæ—¶ä¼šè¦†ç›–\n')
            f.write(' */\n\n')
            
            # è¡€ç³–æ ‡å‡†åŒ–å‚æ•°
            f.write('// =============================================================================\n')
            f.write('// è¡€ç³–æ•°æ®æ ‡å‡†åŒ–å‚æ•° (StandardScaler)\n')
            f.write('// =============================================================================\n\n')
            
            f.write('// è¡€ç³–åºåˆ—çš„å‡å€¼ (ç”¨äºæ ‡å‡†åŒ–: (x - mean) / std)\n')
            f.write('const float glucose_scaler_mean[12] = {\n')
            mean_values = [f'{val:.6f}' for val in glucose_mean]
            f.write('  ' + ', '.join(mean_values) + '\n')
            f.write('};\n\n')
            
            f.write('// è¡€ç³–åºåˆ—çš„æ ‡å‡†å·® (ç”¨äºæ ‡å‡†åŒ–: (x - mean) / std)\n')
            f.write('const float glucose_scaler_std[12] = {\n')
            std_values = [f'{val:.6f}' for val in glucose_std]
            f.write('  ' + ', '.join(std_values) + '\n')
            f.write('};\n\n')
            
            # å‚æ•°æ ‡å‡†åŒ–å‚æ•°
            f.write('// =============================================================================\n')
            f.write('// å‚æ•°æ•°æ®æ ‡å‡†åŒ–å‚æ•° (MinMaxScaler)\n')
            f.write('// =============================================================================\n\n')
            
            f.write('// å‚æ•°çš„æœ€å°å€¼ (ç”¨äºåæ ‡å‡†åŒ–: x * (max - min) + min)\n')
            f.write('const float param_scaler_min[5] = {\n')
            f.write('  // é¡ºåº: [é¢‘ç‡, ç”µæµ, æ—¶é•¿, è„‰å®½, å‘¨æœŸ]\n')
            min_values = [f'{val:.6f}' for val in param_min]
            f.write('  ' + ', '.join(min_values) + '\n')
            f.write('};\n\n')
            
            f.write('// å‚æ•°çš„æœ€å¤§å€¼ (ç”¨äºåæ ‡å‡†åŒ–: x * (max - min) + min)\n')
            f.write('const float param_scaler_max[5] = {\n')
            f.write('  // é¡ºåº: [é¢‘ç‡, ç”µæµ, æ—¶é•¿, è„‰å®½, å‘¨æœŸ]\n')
            max_values = [f'{val:.6f}' for val in param_max]
            f.write('  ' + ', '.join(max_values) + '\n')
            f.write('};\n\n')
            
            # å‚æ•°åç§°å’Œå•ä½
            f.write('// =============================================================================\n')
            f.write('// å‚æ•°åç§°å’Œå•ä½ (ç”¨äºæ˜¾ç¤º)\n')
            f.write('// =============================================================================\n\n')
            
            f.write('const char* param_names[5] = {\n')
            f.write('  "é¢‘ç‡", "ç”µæµ", "æ—¶é•¿", "è„‰å®½", "å‘¨æœŸ"\n')
            f.write('};\n\n')
            
            f.write('const char* param_units[5] = {\n')
            f.write('  "Hz", "mA", "min", "Î¼s", "å‘¨"\n')
            f.write('};\n\n')
            
            # è¾…åŠ©å‡½æ•°
            f.write('// =============================================================================\n')
            f.write('// è¾…åŠ©å‡½æ•°\n')
            f.write('// =============================================================================\n\n')
            
            f.write('// è¡€ç³–æ•°æ®æ ‡å‡†åŒ–å‡½æ•°\n')
            f.write('inline void normalize_glucose_value(float raw_value, int index, float* normalized_value) {\n')
            f.write('  *normalized_value = (raw_value - glucose_scaler_mean[index]) / glucose_scaler_std[index];\n')
            f.write('}\n\n')
            
            f.write('// å‚æ•°æ•°æ®åæ ‡å‡†åŒ–å‡½æ•°\n')
            f.write('inline void denormalize_param_value(float normalized_value, int index, float* param_value) {\n')
            f.write('  *param_value = normalized_value * (param_scaler_max[index] - param_scaler_min[index]) + param_scaler_min[index];\n')
            f.write('}\n\n')
            
            f.write('// éªŒè¯å‚æ•°èŒƒå›´æ˜¯å¦åˆç†\n')
            f.write('inline bool validate_param_range(float param_value, int index) {\n')
            f.write('  return (param_value >= param_scaler_min[index] && param_value <= param_scaler_max[index]);\n')
            f.write('}\n\n')
            
            f.write('#endif // SCALER_PARAMS_H\n')
        
        return True
        
    except Exception as e:
        print(f"âŒ å†™å…¥æ ‡å‡†åŒ–å‚æ•°å¤´æ–‡ä»¶å¤±è´¥: {e}")
        return False

def generate_scaler_params_header(training_dir, output_path):
    """ç”Ÿæˆæ ‡å‡†åŒ–å‚æ•°å¤´æ–‡ä»¶"""
    print(f"ğŸ“„ ç”Ÿæˆæ ‡å‡†åŒ–å‚æ•°å¤´æ–‡ä»¶: {output_path}")
    
    data_processor_path = os.path.join(training_dir, 'data_processor.pkl')
    
    if not os.path.exists(data_processor_path):
        print(f"âŒ æ•°æ®å¤„ç†å™¨æ–‡ä»¶ä¸å­˜åœ¨: {data_processor_path}")
        # å°è¯•æŸ¥æ‰¾training_config.jsonæ–‡ä»¶ä¸­çš„æ ‡å‡†åŒ–å‚æ•°
        config_path = os.path.join(training_dir, 'training_config.json')
        if os.path.exists(config_path):
            print("âš ï¸  å°è¯•ä»training_config.jsonè·å–æ ‡å‡†åŒ–å‚æ•°")
            return generate_scaler_params_from_config(config_path, output_path)
        return False
    
    try:
        # å°è¯•å¯¼å…¥data_processoræ¨¡å—ä»¥æ”¯æŒpickleååºåˆ—åŒ–
        try:
            import data_processor
            print("âœ… æˆåŠŸå¯¼å…¥data_processoræ¨¡å—")
        except ImportError:
            print("âš ï¸  æ— æ³•å¯¼å…¥data_processoræ¨¡å—ï¼Œå°è¯•ä½¿ç”¨å…¼å®¹æ¨¡å¼")
        
        # ä½¿ç”¨weights_only=Falseæ¥é¿å…pickleå®‰å…¨é™åˆ¶
        with open(data_processor_path, 'rb') as f:
            try:
                processor = pickle.load(f)
                print("âœ… æˆåŠŸåŠ è½½data_processor.pklæ–‡ä»¶")
            except Exception as e:
                print(f"âŒ åŠ è½½pickleæ–‡ä»¶å¤±è´¥: {e}")
                # å°è¯•ä½¿ç”¨torch.loadåŠ è½½ï¼ˆå¦‚æœæ˜¯PyTorchä¿å­˜çš„ï¼‰
                try:
                    import torch
                    processor = torch.load(data_processor_path, map_location='cpu', weights_only=False)
                    print("âœ… ä½¿ç”¨torch.loadæˆåŠŸåŠ è½½æ–‡ä»¶")
                except Exception as torch_e:
                    print(f"âŒ torch.loadä¹Ÿå¤±è´¥: {torch_e}")
                    raise e
        
        # æå–æ ‡å‡†åŒ–å‚æ•°
        try:
            glucose_mean = processor.glucose_scaler.mean_
            glucose_std = processor.glucose_scaler.scale_
            param_min = processor.param_scaler.data_min_
            param_max = processor.param_scaler.data_max_
            print("âœ… æˆåŠŸæå–æ ‡å‡†åŒ–å‚æ•°")
        except AttributeError as attr_e:
            print(f"âŒ æå–æ ‡å‡†åŒ–å‚æ•°å¤±è´¥: {attr_e}")
            print("å°è¯•æ‰“å°processorçš„å±æ€§...")
            print(f"processorç±»å‹: {type(processor)}")
            if hasattr(processor, '__dict__'):
                print(f"processorå±æ€§: {list(processor.__dict__.keys())}")
            raise attr_e
        
        # ä½¿ç”¨å…±ç”¨çš„å†™å…¥å‡½æ•°
        success = write_scaler_params_header(output_path, glucose_mean, glucose_std, param_min, param_max, 
                                           source_info=f"è®­ç»ƒæ•°æ® (æ¥æº: {training_dir})")
        
        if success:
            # æ‰“å°å‚æ•°æ‘˜è¦
            print("âœ… æ ‡å‡†åŒ–å‚æ•°å¤´æ–‡ä»¶ç”Ÿæˆå®Œæˆ")
            print("ğŸ“Š å‚æ•°æ‘˜è¦:")
            print(f"   è¡€ç³–å‡å€¼èŒƒå›´: {glucose_mean.min():.2f} ~ {glucose_mean.max():.2f}")
            print(f"   è¡€ç³–æ ‡å‡†å·®èŒƒå›´: {glucose_std.min():.2f} ~ {glucose_std.max():.2f}")
            print(f"   å‚æ•°æœ€å°å€¼: [{param_min[0]:.1f}, {param_min[1]:.1f}, {param_min[2]:.1f}, {param_min[3]:.0f}, {param_min[4]:.1f}]")
            print(f"   å‚æ•°æœ€å¤§å€¼: [{param_max[0]:.1f}, {param_max[1]:.1f}, {param_max[2]:.1f}, {param_max[3]:.0f}, {param_max[4]:.1f}]")
        
        return success
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆæ ‡å‡†åŒ–å‚æ•°å¤´æ–‡ä»¶å¤±è´¥: {e}")
        return False

def generate_conversion_info(training_dir, tflite_path, output_path):
    """ç”Ÿæˆè½¬æ¢ä¿¡æ¯æ–‡ä»¶"""
    print(f"ğŸ“„ ç”Ÿæˆè½¬æ¢ä¿¡æ¯æ–‡ä»¶: {output_path}")
    
    try:
        # è·å–æ¨¡å‹å¤§å°
        model_size = os.path.getsize(tflite_path)
        
        # å°è¯•è¯»å–è®­ç»ƒé…ç½®
        config_path = os.path.join(training_dir, 'training_config.json')
        training_config = {}
        if os.path.exists(config_path):
            with open(config_path, 'r') as f:
                training_config = json.load(f)
        
        # å°è¯•è¯»å–è¯„ä¼°ç»“æœ
        eval_path = os.path.join(training_dir, 'evaluation_results.json')
        eval_results = {}
        if os.path.exists(eval_path):
            with open(eval_path, 'r') as f:
                eval_results = json.load(f)
        
        conversion_info = {
            'generation_info': {
                'timestamp': datetime.now().isoformat(),
                'script_version': '1.0',
                'training_directory': training_dir,
                'tflite_model_path': tflite_path
            },
            'model_info': {
                'input_size': 12,
                'output_size': 5,
                'model_size_bytes': model_size,
                'model_size_kb': round(model_size / 1024, 1)
            },
            'training_config': training_config,
            'evaluation_results': eval_results,
            'arduino_files': {
                'main_program': 'esp32_tavns_test.ino',
                'model_data': 'tavns_model_data.h',
                'scaler_params': 'scaler_params.h',
                'readme': 'README.md'
            },
            'usage_instructions': {
                'step1': 'åœ¨Arduino IDEä¸­æ‰“å¼€esp32_tavns_test.ino',
                'step2': 'é€‰æ‹©ESP32S3 Dev Moduleå¼€å‘æ¿',
                'step3': 'é…ç½®PSRAMå’Œåˆ†åŒºæ–¹æ¡ˆ',
                'step4': 'ç¼–è¯‘å¹¶ä¸Šä¼ åˆ°ESP32-S3',
                'step5': 'æ‰“å¼€ä¸²å£ç›‘è§†å™¨æŸ¥çœ‹æµ‹è¯•ç»“æœ'
            }
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(conversion_info, f, indent=2, ensure_ascii=False)
        
        print("âœ… è½¬æ¢ä¿¡æ¯æ–‡ä»¶ç”Ÿæˆå®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆè½¬æ¢ä¿¡æ¯æ–‡ä»¶å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Arduinoæ–‡ä»¶ç”Ÿæˆå™¨')
    parser.add_argument('--float32', action='store_true', 
                       help='ä¼˜å…ˆä½¿ç”¨Float32éé‡åŒ–æ¨¡å‹ï¼ˆé»˜è®¤ï¼Œä¸“ä¸ºESP32-S3ä¼˜åŒ–ï¼‰')
    parser.add_argument('--quantized', action='store_true', 
                       help='ä¼˜å…ˆä½¿ç”¨é‡åŒ–ä¼˜åŒ–æ¨¡å‹')
    
    args = parser.parse_args()
    
    # ç¡®å®šæ¨¡å‹åå¥½ - é»˜è®¤ä¼˜å…ˆFloat32
    if args.quantized:
        prefer_float32 = False
        mode_desc = "é‡åŒ–ä¼˜åŒ–"
    else:
        prefer_float32 = True
        mode_desc = "Float32éé‡åŒ–ï¼ˆé»˜è®¤ï¼‰"
    
    print("ğŸš€ Arduinoæ–‡ä»¶ç”Ÿæˆå™¨")
    print("=" * 50)
    print(f"ğŸ”§ æ¨¡å‹åå¥½: {mode_desc}æ¨¡å¼")
    
    # æ£€æŸ¥Arduino_Testç›®å½•
    arduino_dir = 'Arduino_Test'
    if not os.path.exists(arduino_dir):
        print(f"âŒ Arduino_Testç›®å½•ä¸å­˜åœ¨")
        return False
    
    # æŸ¥æ‰¾æœ€æ–°çš„è®­ç»ƒè¾“å‡º
    training_dir = find_latest_training_output()
    if not training_dir:
        return False
    
    # æŸ¥æ‰¾æœ€æ–°çš„TFLiteæ¨¡å‹
    tflite_path = find_latest_tflite_model(prefer_float32)
    if not tflite_path:
        return False
    
    print("\nğŸ“ å¼€å§‹ç”ŸæˆArduinoæ–‡ä»¶...")
    
    success_count = 0
    total_count = 3
    
    # ç”Ÿæˆæ¨¡å‹æ•°æ®å¤´æ–‡ä»¶
    if generate_model_data_header(tflite_path, os.path.join(arduino_dir, 'tavns_model_data.h')):
        success_count += 1
    
    # ç”Ÿæˆæ ‡å‡†åŒ–å‚æ•°å¤´æ–‡ä»¶
    if generate_scaler_params_header(training_dir, os.path.join(arduino_dir, 'scaler_params.h')):
        success_count += 1
    
    # ç”Ÿæˆè½¬æ¢ä¿¡æ¯æ–‡ä»¶
    if generate_conversion_info(training_dir, tflite_path, os.path.join(arduino_dir, 'conversion_info.json')):
        success_count += 1
    
    print("\n" + "=" * 50)
    if success_count == total_count:
        # æ£€æµ‹ä½¿ç”¨çš„æ¨¡å‹ç±»å‹
        model_type = "Float32éé‡åŒ–" if 'float32' in os.path.basename(tflite_path) else "é‡åŒ–ä¼˜åŒ–"
        model_size_mb = os.path.getsize(tflite_path) / (1024 * 1024)
        
        print("ğŸ‰ æ‰€æœ‰Arduinoæ–‡ä»¶ç”Ÿæˆå®Œæˆ!")
        print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {arduino_dir}")
        print(f"ğŸ”§ æ¨¡å‹ç±»å‹: {model_type} ({model_size_mb:.1f} MB)")
        
        print("\nğŸ“‹ ç”Ÿæˆçš„æ–‡ä»¶:")
        print(f"   âœ… tavns_model_data.h - TensorFlow Liteæ¨¡å‹æ•°æ® ({model_type})")
        print("   âœ… scaler_params.h - æ•°æ®æ ‡å‡†åŒ–å‚æ•°") 
        print("   âœ… conversion_info.json - è½¬æ¢ä¿¡æ¯")
        
        print("\nğŸ”§ ä¸‹ä¸€æ­¥:")
        print("   1. åœ¨Arduino IDEä¸­æ‰“å¼€esp32_tavns_test.ino")
        print("   2. é€‰æ‹©ESP32S3å¼€å‘æ¿å¹¶é…ç½®å‚æ•°")
        print("   3. ç¼–è¯‘å¹¶ä¸Šä¼ åˆ°ESP32-S3")
        print("   4. æ‰“å¼€ä¸²å£ç›‘è§†å™¨æŸ¥çœ‹æµ‹è¯•ç»“æœ")
        
        if 'float32' in os.path.basename(tflite_path):
            print("\nğŸ’¡ æç¤º: ä½¿ç”¨Float32éé‡åŒ–æ¨¡å‹ï¼ˆé»˜è®¤ï¼‰ï¼Œä¸“ä¸ºESP32-S3 TFLite Microä¼˜åŒ–")
        else:
            print("\nğŸ’¡ æç¤º: å¦‚æœESP32è¾“å‡ºå›ºå®šå€¼ï¼Œå»ºè®®ä½¿ç”¨é»˜è®¤çš„Float32éé‡åŒ–æ¨¡å¼")
            
        return True
    else:
        print(f"âš ï¸  éƒ¨åˆ†æ–‡ä»¶ç”Ÿæˆå¤±è´¥ ({success_count}/{total_count})")
        return False

if __name__ == '__main__':
    success = main()
    exit(0 if success else 1) 