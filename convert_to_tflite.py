#!/usr/bin/env python3

import os
import sys
import json
import numpy as np
import torch
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from model import taVNSNet
from data_processor import taVNSDataProcessor

class TFLiteConverter:
    """PyTorchåˆ°TensorFlow Liteè½¬æ¢å™¨"""
    
    def __init__(self, model_path, output_dir="tflite_output"):
        """
        åˆå§‹åŒ–è½¬æ¢å™¨
        
        Args:
            model_path: PyTorchæ¨¡å‹æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
        """
        self.model_path = model_path
        self.output_dir = output_dir
        self.data_processor = taVNSDataProcessor()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # æ¨¡å‹é…ç½®
        self.input_shape = (12,)  # è¡€ç³–åºåˆ—é•¿åº¦
        self.output_shape = (5,)  # åˆºæ¿€å‚æ•°æ•°é‡
        self.hidden_size = 128
        self.num_layers = 2
        self.dropout = 0.2
        
    def load_pytorch_model(self):
        """åŠ è½½PyTorchæ¨¡å‹"""
        print("æ­£åœ¨åŠ è½½PyTorchæ¨¡å‹...")
        
        # åˆ›å»ºæ¨¡å‹å®ä¾‹
        model = taVNSNet(
            input_dim=12,
            param_dim=5,
            hidden_dim=self.hidden_size,
            num_layers=self.num_layers,
            dropout=self.dropout
        )
        
        # åŠ è½½æƒé‡
        checkpoint = torch.load(self.model_path, map_location='cpu', weights_only=False)
        if 'model_state_dict' in checkpoint:
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint)
        
        model.eval()
        print(f"æ¨¡å‹å·²åŠ è½½: {self.model_path}")
        return model
    
    def create_keras_model(self):
        """åˆ›å»ºç­‰æ•ˆçš„Kerasæ¨¡å‹"""
        print("æ­£åœ¨åˆ›å»ºKerasæ¨¡å‹...")
        
        # è¾“å…¥å±‚
        inputs = keras.Input(shape=self.input_shape, name='glucose_input')
        
        # é‡å¡‘ä¸ºåºåˆ—æ ¼å¼ (batch_size, sequence_length, features)
        x = layers.Reshape((self.input_shape[0], 1))(inputs)
        
        # LSTMå±‚
        lstm_output = layers.LSTM(
            units=self.hidden_size,
            return_sequences=True,
            dropout=self.dropout,
            name='lstm_layer'
        )(x)
        
        # å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶
        attention_output = layers.MultiHeadAttention(
            num_heads=4,
            key_dim=self.hidden_size // 4,
            dropout=self.dropout,
            name='multi_head_attention'
        )(lstm_output, lstm_output)
        
        # æ®‹å·®è¿æ¥å’Œå±‚å½’ä¸€åŒ–
        x = layers.Add()([lstm_output, attention_output])
        x = layers.LayerNormalization(epsilon=1e-6)(x)
        
        # å…¨å±€å¹³å‡æ± åŒ–
        x = layers.GlobalAveragePooling1D()(x)
        
        # å…¨è¿æ¥å±‚
        x = layers.Dense(128, activation='relu', name='fc1')(x)
        x = layers.Dropout(self.dropout)(x)
        x = layers.Dense(64, activation='relu', name='fc2')(x)
        x = layers.Dropout(self.dropout)(x)
        
        # è¾“å‡ºå±‚ - åˆºæ¿€å‚æ•°é¢„æµ‹
        outputs = layers.Dense(
            self.output_shape[0], 
            activation='linear', 
            name='stim_params_output'
        )(x)
        
        # åˆ›å»ºæ¨¡å‹
        keras_model = keras.Model(inputs=inputs, outputs=outputs, name='taVNS_TFLite')
        
        print("Kerasæ¨¡å‹å·²åˆ›å»º")
        return keras_model
    
    def convert_to_tflite(self, keras_model):
        """è½¬æ¢ä¸ºTFLiteæ ¼å¼"""
        print("æ­£åœ¨è½¬æ¢ä¸ºTFLiteæ ¼å¼...")
        
        # åˆ›å»ºTFLiteè½¬æ¢å™¨
        converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)
        
        # è®¾ç½®ä¼˜åŒ–é€‰é¡¹
        converter.optimizations = [tf.lite.Optimize.DEFAULT]
        
        # è®¾ç½®ç›®æ ‡è§„èŒƒï¼ˆç”¨äºå¾®æ§åˆ¶å™¨ï¼‰- ä¿®å¤LSTMè½¬æ¢é—®é¢˜
        converter.target_spec.supported_ops = [
            tf.lite.OpsSet.TFLITE_BUILTINS,
            tf.lite.OpsSet.SELECT_TF_OPS
        ]
        
        # ç¦ç”¨TensorListæ“ä½œé™ä½
        converter._experimental_lower_tensor_list_ops = False
        
        # è®¾ç½®æ”¯æŒçš„ç±»å‹
        converter.target_spec.supported_types = [tf.float32]
        
        # è½¬æ¢æ¨¡å‹
        tflite_model = converter.convert()
        
        # ä¿å­˜TFLiteæ¨¡å‹
        tflite_path = os.path.join(self.output_dir, "tavns_model.tflite")
        with open(tflite_path, 'wb') as f:
            f.write(tflite_model)
        
        print(f"TFLiteæ¨¡å‹å·²ä¿å­˜: {tflite_path}")
        return tflite_path
    
    def test_tflite_model(self, tflite_path):
        """æµ‹è¯•TFLiteæ¨¡å‹"""
        print("æ­£åœ¨æµ‹è¯•TFLiteæ¨¡å‹...")
        
        # åŠ è½½TFLiteæ¨¡å‹
        interpreter = tf.lite.Interpreter(model_path=tflite_path)
        interpreter.allocate_tensors()
        
        # è·å–è¾“å…¥è¾“å‡ºè¯¦æƒ…
        input_details = interpreter.get_input_details()
        output_details = interpreter.get_output_details()
        
        print(f"è¾“å…¥è¯¦æƒ…: {input_details}")
        print(f"è¾“å‡ºè¯¦æƒ…: {output_details}")
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        test_input = np.random.random((1, 12)).astype(np.float32)
        
        # è®¾ç½®è¾“å…¥
        interpreter.set_tensor(input_details[0]['index'], test_input)
        
        # è¿è¡Œæ¨ç†
        interpreter.invoke()
        
        # è·å–è¾“å‡º
        output = interpreter.get_tensor(output_details[0]['index'])
        
        print(f"æµ‹è¯•è¾“å…¥å½¢çŠ¶: {test_input.shape}")
        print(f"æµ‹è¯•è¾“å‡ºå½¢çŠ¶: {output.shape}")
        print(f"æµ‹è¯•è¾“å‡º: {output.flatten()}")
        
        return output.flatten()
    
    def create_model_info(self, tflite_path):
        """åˆ›å»ºæ¨¡å‹ä¿¡æ¯æ–‡ä»¶"""
        print("æ­£åœ¨åˆ›å»ºæ¨¡å‹ä¿¡æ¯æ–‡ä»¶...")
        
        # è·å–æ¨¡å‹å¤§å°
        with open(tflite_path, 'rb') as f:
            model_size = len(f.read())
        
        info = {
            "model_name": "taVNSå‚æ•°é¢„æµ‹æ¨¡å‹",
            "version": "1.0",
            "model_format": "TensorFlow Lite",
            "model_size_bytes": model_size,
            "input_shape": self.input_shape,
            "output_shape": self.output_shape,
            "input_description": "è¡€ç³–åºåˆ— (12ä¸ªç‚¹ï¼Œæ¯5åˆ†é’Ÿä¸€ä¸ª)",
            "output_description": "taVNSåˆºæ¿€å‚æ•° [é¢‘ç‡(Hz), ç”µæµ(mA), æ—¶é•¿(åˆ†é’Ÿ), è„‰å®½(Î¼s), å‘¨æœŸ(å‘¨)]",
            "model_architecture": {
                "hidden_size": self.hidden_size,
                "num_layers": self.num_layers,
                "dropout": self.dropout
            },
            "target_platform": "ESP32-S3",
            "framework": "TensorFlow Lite",
            "optimization": "é‡åŒ–ä¼˜åŒ–",
            "notes": [
                "æ¨¡å‹åŸºäºä¸‰ç¯‡ç§‘å­¦è®ºæ–‡æ•°æ®è®­ç»ƒ",
                "æ”¯æŒ2/15 Hzäº¤æ›¿åˆºæ¿€æ¨¡å¼",
                "é€‚ç”¨äºç³–å°¿ç—…è¡€ç³–ç®¡ç†",
                "æ”¯æŒä¸ªä½“åŒ–å‚æ•°è°ƒæ•´",
                "å¯ç›´æ¥ç”¨äºArduino ESP32-S3é¡¹ç›®"
            ]
        }
        
        # ä¿å­˜ä¿¡æ¯æ–‡ä»¶
        info_path = os.path.join(self.output_dir, "model_info.json")
        with open(info_path, 'w', encoding='utf-8') as f:
            json.dump(info, f, indent=2, ensure_ascii=False)
        
        print(f"æ¨¡å‹ä¿¡æ¯æ–‡ä»¶å·²ä¿å­˜: {info_path}")
        return info_path
    
    def create_model_weights_info(self, model):
        """åˆ›å»ºæ¨¡å‹æƒé‡ä¿¡æ¯æ–‡ä»¶"""
        print("æ­£åœ¨åˆ›å»ºæ¨¡å‹æƒé‡ä¿¡æ¯æ–‡ä»¶...")
        
        weights_info = {
            "model_path": self.model_path,
            "total_parameters": 0,
            "trainable_parameters": 0,
            "layers": []
        }
        
        total_params = 0
        trainable_params = 0
        
        for name, param in model.named_parameters():
            layer_info = {
                "name": name,
                "shape": list(param.shape),
                "parameters": param.numel(),
                "requires_grad": param.requires_grad
            }
            weights_info["layers"].append(layer_info)
            
            total_params += param.numel()
            if param.requires_grad:
                trainable_params += param.numel()
        
        weights_info["total_parameters"] = total_params
        weights_info["trainable_parameters"] = trainable_params
        
        # ä¿å­˜æƒé‡ä¿¡æ¯æ–‡ä»¶
        weights_path = os.path.join(self.output_dir, "model_weights_info.json")
        with open(weights_path, 'w', encoding='utf-8') as f:
            json.dump(weights_info, f, indent=2, ensure_ascii=False)
        
        print(f"æ¨¡å‹æƒé‡ä¿¡æ¯æ–‡ä»¶å·²ä¿å­˜: {weights_path}")
        return weights_path
    
    def create_conversion_report(self, test_output):
        """åˆ›å»ºè½¬æ¢æŠ¥å‘Š"""
        print("æ­£åœ¨åˆ›å»ºè½¬æ¢æŠ¥å‘Š...")
        
        report = {
            "conversion_status": "æˆåŠŸè½¬æ¢ä¸ºTensorFlow Liteæ ¼å¼",
            "model_test_results": {
                "input_shape": self.input_shape,
                "output_shape": self.output_shape,
                "test_output": test_output.tolist(),
                "test_output_description": "taVNSåˆºæ¿€å‚æ•° [é¢‘ç‡(Hz), ç”µæµ(mA), æ—¶é•¿(åˆ†é’Ÿ), è„‰å®½(Î¼s), å‘¨æœŸ(å‘¨)]"
            },
            "arduino_usage": [
                "1. å°† tavns_model.tflite å¤åˆ¶åˆ°Arduinoé¡¹ç›®",
                "2. å®‰è£…TensorFlow Lite ESP32åº“",
                "3. ä½¿ç”¨TFLiteInterpreteråŠ è½½æ¨¡å‹",
                "4. åœ¨ESP32-S3ä¸Šè¿è¡Œæ¨ç†"
            ],
            "arduino_requirements": [
                "Arduino IDE",
                "ESP32å¼€å‘æ¿æ”¯æŒ",
                "TensorFlow Lite ESP32åº“",
                "ESP32-S3å¼€å‘æ¿"
            ]
        }
        
        # ä¿å­˜è½¬æ¢æŠ¥å‘Š
        report_path = os.path.join(self.output_dir, "conversion_report.json")
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"è½¬æ¢æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
        return report_path
    
    def convert(self):
        """æ‰§è¡Œè½¬æ¢æµç¨‹"""
        print("=== taVNSæ¨¡å‹è½¬æ¢å¼€å§‹ ===")
        
        try:
            # 1. åŠ è½½PyTorchæ¨¡å‹
            pytorch_model = self.load_pytorch_model()
            
            # 2. åˆ›å»ºKerasæ¨¡å‹
            keras_model = self.create_keras_model()
            
            # 3. è½¬æ¢ä¸ºTFLiteæ ¼å¼
            tflite_path = self.convert_to_tflite(keras_model)
            
            # 4. æµ‹è¯•TFLiteæ¨¡å‹
            test_output = self.test_tflite_model(tflite_path)
            
            # 5. åˆ›å»ºæ¨¡å‹ä¿¡æ¯æ–‡ä»¶
            info_path = self.create_model_info(tflite_path)
            
            # 6. åˆ›å»ºæ¨¡å‹æƒé‡ä¿¡æ¯æ–‡ä»¶
            weights_path = self.create_model_weights_info(pytorch_model)
            
            # 7. åˆ›å»ºè½¬æ¢æŠ¥å‘Š
            report_path = self.create_conversion_report(test_output)
            
            # 8. è·å–æœ€ç»ˆæ¨¡å‹å¤§å°
            with open(tflite_path, 'rb') as f:
                model_size = len(f.read())
            
            print("\n=== è½¬æ¢å®Œæˆ ===")
            print(f"è¾“å‡ºç›®å½•: {self.output_dir}")
            print(f"TFLiteæ¨¡å‹: {tflite_path}")
            print(f"æ¨¡å‹å¤§å°: {model_size} å­—èŠ‚")
            print(f"æ¨¡å‹ä¿¡æ¯: {info_path}")
            print(f"æƒé‡ä¿¡æ¯: {weights_path}")
            print(f"è½¬æ¢æŠ¥å‘Š: {report_path}")
            print(f"æµ‹è¯•è¾“å‡º: {test_output}")
            
            return True
            
        except Exception as e:
            print(f"è½¬æ¢å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

def main():
    """ä¸»å‡½æ•°"""
    # æŸ¥æ‰¾æœ€æ–°çš„è®­ç»ƒè¾“å‡º
    training_outputs_dir = "Training_Outputs"
    if not os.path.exists(training_outputs_dir):
        print("é”™è¯¯: æ‰¾ä¸åˆ°Training_Outputsç›®å½•")
        return
    
    # æŸ¥æ‰¾æœ€æ–°çš„best_model.pth
    latest_model = None
    
    for item in os.listdir(training_outputs_dir):
        item_path = os.path.join(training_outputs_dir, item)
        if os.path.isdir(item_path):
            model_path = os.path.join(item_path, "best_model.pth")
            if os.path.exists(model_path):
                if not latest_model or item > latest_model:
                    latest_model = item
    
    if not latest_model:
        print("é”™è¯¯: æ‰¾ä¸åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶")
        return
    
    model_path = os.path.join(training_outputs_dir, latest_model, "best_model.pth")
    print(f"ä½¿ç”¨æ¨¡å‹: {model_path}")
    
    # åˆ›å»ºè½¬æ¢å™¨å¹¶æ‰§è¡Œè½¬æ¢
    converter = TFLiteConverter(model_path)
    success = converter.convert()
    
    if success:
        print("\nğŸ‰ è½¬æ¢æˆåŠŸ!")
        print("\nğŸ“‹ æ¨¡å‹æ–‡ä»¶å·²å‡†å¤‡å°±ç»ª:")
        print("1. tavns_model.tflite - Arduinoå¯ç”¨çš„TensorFlow Liteæ¨¡å‹")
        print("2. model_info.json - æ¨¡å‹è¯¦ç»†ä¿¡æ¯")
        print("3. model_weights_info.json - æ¨¡å‹æƒé‡ä¿¡æ¯")
        print("4. conversion_report.json - è½¬æ¢æŠ¥å‘Š")
        print("\nğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
        print("1. å°† tavns_model.tflite å¤åˆ¶åˆ°Arduinoé¡¹ç›®")
        print("2. ä½¿ç”¨TensorFlow Lite ESP32åº“åŠ è½½æ¨¡å‹")
        print("3. åœ¨ESP32-S3ä¸Šè¿è¡Œæ¨ç†")
    else:
        print("\nâŒ è½¬æ¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

if __name__ == "__main__":
    main() 